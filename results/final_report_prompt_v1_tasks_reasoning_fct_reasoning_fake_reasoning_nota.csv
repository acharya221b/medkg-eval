model_name,task_name,total,correct,wrong,accuracy_%,simple_score,penalty_score
deepseek-r1:14b,reasoning_fake,20,11,9,55.00000000000001,11,8.75
llama3.2:latest,reasoning_fake,20,18,2,90.0,18,17.5
deepseek-r1:14b,reasoning_fct,20,1,19,5.0,1,-3.75
llama3.2:latest,reasoning_fct,20,0,20,0.0,0,-5.0
deepseek-r1:14b,reasoning_nota,20,11,9,55.00000000000001,11,8.75
llama3.2:latest,reasoning_nota,20,3,17,15.0,3,-1.25
