model_name,task_name,total,correct,wrong,accuracy_%,simple_score,penalty_score
deepseek-r1:14b,reasoning_fake,20,13,7,65.0,13,11.25
llama3.2:latest,reasoning_fake,20,12,8,60.0,12,10.0
deepseek-r1:14b,reasoning_fct,20,2,18,10.0,2,-2.5
llama3.2:latest,reasoning_fct,20,1,19,5.0,1,-3.75
deepseek-r1:14b,reasoning_nota,20,7,13,35.0,7,3.75
llama3.2:latest,reasoning_nota,20,4,16,20.0,4,0.0
