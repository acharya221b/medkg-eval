model_name,task_name,total,correct,wrong,accuracy_%,penalty_score
deepseek-r1:14b,reasoning_fake,20,16,4,80.0,15.0
llama3.2:latest,reasoning_fake,20,17,3,85.0,16.25
deepseek-r1:14b,reasoning_fct,20,3,17,15.0,-1.25
llama3.2:latest,reasoning_fct,20,1,19,5.0,-3.75
deepseek-r1:14b,reasoning_nota,20,10,10,50.0,7.5
llama3.2:latest,reasoning_nota,20,2,18,10.0,-2.5
